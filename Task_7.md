# MLSecOps: замок для ящика пандоры
## Основные моменты доклада
### Проблематика ML-моделей
Для ML-моделей возникают уникальные угрозы и, вместе с тем, сохраняются класические.  
На момент доклада более 30 инструментов для проведения атак на ML-модели находятся в отрытом доступе.  
#### Терминология
Система искусственного интеллекта - одна или несколько моделей искусственного интеллекта для решения определённой задачи.  
Сильный искусственный интеллект - сопоставим с человеческими возможностями или превосходит их (не создан на момент доклада).  
Слабый искусственный интеллект - Результат машинного обучения, полученный в ходе оптимизации ML-моделей. Используется для решения узких прикладных задач.  

#### Основные типы машинного обучения

<table>
  <thead>
    <tr>
      <th colspan="3">Типы машинного обучения</th>
    </tr>
    <tr>
      <th>Обучение с учителем</th>
      <th>Обучение без учителя</th>
      <th>Обучение с подкреплением</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td valign="top">
        Например:
        <ul>
          <li>Классификация писем (spam detection)</li>
          <li>Распознавание изображений</li>
          <li>Регрессия (численное предсказание значений)</li>
        </ul>
      </td>
      <td valign="top">
        Например:
        <ul>
        <li>Кластеризация (выделение определённых признаков)</li>
        <li>Снижение размерности (в т.ч. распознавание лиц)</li>
          </ul>
      </td>
      <td valign="top">
        Например:
        <ul>
        <li>Создание беспилотного транспорта</li>
        <li>Промышленная робототехника</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="top">
        Нейросети: <br>
        MLP, CNN, RNN, LSTM, GRU, Transformer
      </td>
      <td valign="top">
        Нейросети: <br>
        Autoencoder, VAE, GAN, Self-supervised Transformers
      </td>
      </td>
      <td valign="top">
        Нейросети: <br>
        DQN, CNN+RL, RNN+RL, Transformers+RL
      </td>
    </tr>
        <tr>
      <td valign="top">
        <ul>
        <li>Обучающие размеченные данные. <br>
        Данным присваиваются метки, чтобы модель изучиле признаки, по которым в дальнейшем она будет работать</li>
        <li>Валидационные размеченные данные. <br> 
        Используются для подбора параметров обучения</li>
        <li>Тестовые размеченные данные. <br> 
        Используются для оценки качества модели</li>
        </ul>
      </td>
      <td valign="top">
        <ul>
        <li>Обучающие неразмеченные данные</li>
        <li>Валидационные неразмеченные данные*</li>
        <li>Тестовые неразмеченные данные*</li>
        </ul>
        *применяются опционально
      </td>
      </td>
      <td valign="top">
        <ul> 
        <li>Обучающие динамические данные.</li>
        <li>За правильное выполнение функций модель получает баллы</li>
        <li>Модель оценивается в рамках метрик на основе баллов</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

Результатом обучения является ML-модель.  
По автономности и способности принимать решения без сторонней помощи ML-модели классифицируют:
- Функциональные модели. Получают входные данные, обрабатывают, возвращают выходные. Минимальная автономность
- Агенты. Информационные системы, взаимодействующие с функциональными моделями. Имеют автономность, память и планирование действий. Средняя автономность
- Мультиагентные системы. Большая задача разбивается на подзадачи и каждый агент выполняет свою подзадачу. Могут включать координирующий агент. Наибольшая автономность

С повышением автономности повышается вероятный ущерб в результате действий системы.  

### MLSecOps: объекты защиты и уникальные угрозы
MLSecOps - набор практик интеграции процессов обеспечения и управления ИБ во все этапы жизненного цикла ML-систем.  
Является надстройкой над DevSecOps и развитием MLOps.  
Цели MLSecOps: 
- конфиденциальность данных и МL-моделей
- целостность данных, кода и МL-моделей
- доступность МL-систем
- защита ИТ-инфраструктуры и МL-систем от атак

<table>
  <thead>
    <tr>
      <th colspan="2">Объекты защиты</th>
    </tr>
    <tr>
      <th>Базовые объекты защиты DevSecOps</th>
      <th>Новые объекты защиты MLSecOps</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td valign="top">
        <ul>
          <li>Компоненты</li>
          <li>Окружение разработки</li>
          <li>Среда эксплуатации</li>
          <li>Приложение</li>
        </ul>
        <td valign="top">
        <ul>
          <li>Данные</li>
          <li>ML-модели</li>
          <li>Потоки данных</li>
          <li>Привилегии</li>
        </ul>
        </td>
    </tr>
  </tbody>
</table>

Упрощенный пайплайн ML-систем:
1. **Сбор данных**. Подготовка требований к данным, анализ их происхождения, сбор инф-ции.
2. **Предобработка данных**. Очистка данных, разделение на обучающую, валидационную и тестовую выборки.
3. **Выбор ML-моделей**. Выбор архитектур и библиотек для создания ML-моделей.
4. **Обучение ML-моделей**.
5. **Верификация и валидация**.
6. **Публикация ML-модели в реестре**.
7. **Развёртывание ML-модели**.
8. **Мониторинг**

Внедрение MLSecOps требуется для:
- Разработчиков ML-моделей
- Разработчиков продуктов и услуг с применением ML-моделей
- Заказчиков продуктов на базе ML-моделей

Уникальные угрозы для функциональных ML-моделей:
- Кража ML-модели
- Кража конфиденциальной информации, на которой обучалась ML-модель
- Обход логики работы ML-модели
- Нарушение логики работы ML-модели
- DoS-атаки на ML-модель
- Проникновение в ИТ-инфраструктуру, путём внедрения кода в ML-модель

Уникальные угрозы для агентов и мультиагентных систем
- Актуальны угрозы, описанные для функциональных ML-моделей
- Избыточные привилегии у агентов
- Цепной обход логики агентов
- MITM-атака на взаимодействие агентов
- Отравление памяти агентов
        
### Мероприятия и инструменты обеспечения ИБ ML-моделей
<table>
  <thead>
    <tr>
      <th colspan="2">Мероприятия обеспечения ИБ ML-моделей</th>
    </tr>
    <tr>
      <th>Мероприятия</th>
      <th>Атаки</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td valign="top">
        <ul>
          <li>Документирование и внедрение процессов управления данными</li>
          <li>Назначение ответственных</li>
          <li>Инвентаризация артефактов ML-систем (метаданные обучения и ML-моделей)</li>
          <li>Контроль отсутствия конф. инф-ции в обучающих данных (без необходимости)</li>
          <li>Контроль отсутствия сведений об обучающих данных в свободном доступе</li>
          <li>Контроль отсутствия состязательных атак в обучающих данных</li>
          <li>Контроль отсутствия обучения ML-модели на данных, полученных от пользователя </li>
          <li>Использование ансамблей ML-моделей (различных архитектур) для устойчивости к атакам</li>
          <li>Контроль отсутствия сведений об архитектуре модели в свободном доступе</li>
        </ul>
        <td valign="top">
        <ul>
          <li>Кража конф. инф-ции из обучающей выборки</li>
          <li>Нарущение логики работы ML-модели</li>
          <li>(Цепной) обход логики работы ML-моделей</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="top">
        <ul>
          <li>Ограничение количества и скорости запросов к ML-системам</li>
          <li>Ограничение ввода и вывода ML-систем количеством и набором символов, форматом</li>
          <li>Изменение параметров входных и выходных данных (пред- и постобработка)</li>
          <li>МL-модель не хранится на конечном устройстве</li>
          <li>ML-модель запускается в изолированной сетевой среде</li>
          <li>ML-модели имеют минимальные привилегии</li>
          <li>В ML-моделях используется ролевое управление доступом</li>
          <li>ВЗаимодействие ML-моделей происходит с использованием алгоритмов шифрования</li>
          <li>Обучение пользователей и разработчиков ML-систем правилам использования рискам ИБ</li>
        </ul>
        <td valign="top">
        <ul>
          <li>DoS-атаки на ML-модель</li>
          <li>(Цепной) обход логики работы ML-моделей</li>
          <li>Кража ML-модели</li>
          <li>Проникновение в инфраструктуру</li>
          <li>Избыточные привилегии агентов</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>




<table>
  <thead>
    <tr>
      <th colspan="2">Инструменты обеспечения ИБ ML-моделей</th>
    </tr>
    <tr>
      <th>Мероприятия</th>
      <th>Инструменты</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td valign="top">
        Очистка данных от конфиденциальной информации
      </td>
      <td valign="top">
        <ul>
          <li>Purify</li>
          <li>Presidio</li>
          <li>ARX</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Обнаружение статистических выбросов
      </td>
      <td valign="top">
        <ul>
          <li>Pandas</li>
          <li>Seaborn</li>
          <li>Alibi Setect</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Обнаружение отравления обучающей выборки (изображений)
      </td>
      <td valign="top">
        <ul>
          <li>ART</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Защита от ата на сериализацию модели
      </td>
      <td valign="top">
        <ul>
          <li>Modelscan</li>
          <li>Safetensors</li>
          <li>Modelaudit</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Обучение моделей с использованием дифференциальной конфиденциальности
      </td>
      <td valign="top">
        <ul>
          <li>Opacus</li>
          <li>Diffprivib</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Состязательные атаки в обучении
      </td>
      <td valign="top">
        <ul>
          <li>ART</li>
          <li>FoolBox</li>
        </ul>
        </td>
    </tr>
    <tr>
      <td valign="top">
        Обнаружение возможности успешного проведения так
      </td>
      <td valign="top">
        <ul>
          <li>ART</li>
          <li>FoolBox</li>
          <li>Llamator</li>
          <li>Garak</li>
          <li>PromptFoo</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="top">
        Цифровая подпись модели
      </td>
      <td valign="top">
        <ul>
          <li>Cosign</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="top">
        Контроль активности агентов; защита входящих запросов и исходящих ответов; детектирование состязательных атак
      <td valign="top">
        <ul>
          <li>Hive Trace</li>
          <li>NeMo GuardRails</li>
          <li>GuardRail</li>
          <li>LLM Guard</li>
        </ul>
      </td>
    </tr>
    <tr>
      <td valign="top">
        Предобработка параметров входных данных ML-систем
      <td valign="top">
        <ul>
          <li>ART</li>
        </ul>
      </td>
    </tr>
    </tr>
    <tr>
      <td valign="top">
        Мониторинг и проверка работоспособности ПО (производительность, качество, целостность)
      <td valign="top">
        <ul>
          <li>Evidently</li>
          <li>Prometheus</li>
          <li>Grafana</li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-1.jpg">
</p>

### Фреймворк, объединяющий DevSecOps и MLSecOps
Фреймворк разработан компанией Jet  
DAF - фреймворк для оценки DevSecOps и он имеет дополнительное расширение для использования MLSecOps

### Шаги выстраивания MLSecOps
1. Аудит ИБ ML-систем
   - аудит ML-систем
   - аудит обеспечения и управления ИБ
   - аудит ИТ- и сетевой инфраструктуры
   - аудит СЗИ
2. Моделирование угроз и анализ рисков ИБ ML-систем
   - различные способы (диаграммы потоков данных, STRIDE, OWASP GenAI Security Project, MITRE ATLAS, DREAD, ISO 27005 и др.)
3. Формирование и реализация дорожной карты развития MLSecOps
   - внедрение конкретных процессов и инструментов с учетом результатов аудита и анализа рисков ИБ

___
## Ящик Пандоры
> Ты — инженер **DevSecOps**, начинающий погружаться в новый мир **MLSecOps**. Руководитель поручил тебе протестировать информационную безопасность нескольких ML-моделей перед их размещением в продуктовой среде.
> 
> Все нужные инструменты, библиотеки, зависимости и ML-модели уже находятся на ВМ, доступ в Интернет не требуется. Устанавливай Oracle VirtualBox, скачивай и запускай образ ВМ с ОС Ubuntu 22.04 ([ссылка](https://files.jet.su/d/swkqw2n9) и [зеркало](https://disk.360.yandex.com/d/JIIbuzeFEoF4Wg)), заходи в папку `/home/user/Documents/todo` — и приступай к выполнению задания. Мы даём тебе на выбор терминал и лёгкую графическую среду рабочего стола LXDE.
> 
> Логин: `user`
> Пароль: `strong_password`
> 
> Для выполнения заданий понадобится запустить инструменты и Python-скрипты из виртуального окружения Python:
> 
>     user@pandora-box:~$ cd Documents/todo/
> 
>     user@pandora-box:~/Documents/todo$ source myenv/bin/activate
> 
> Минимальные системные требования:
> 2 ЦП, 4 ГБ ОЗУ, 25 ГБ места на жёстком диске. Наличие видеокарты не обязательно.
> 
> Тебе также пригодятся эти материалы:
> 
> - https://pypi.org/project/modelaudit/
> - https://github.com/NVIDIA/garak
> - https://reference.garak.ai/en/latest/configurable.html
> - https://docs.sigstore.dev/cosign/
> - https://github.com/protectai/llm-guard

> "Беды, представленные в Ящике Пандоры - последствия неконтролируемого использования высокопривилегированных и автономных агентных и мультиагентных систем"
___

Для выполнения заданий предлагается виртуальная машина (описана в задании) для VirtualBox. Для корректного запуска следует отключить первый сетевой интерфейс - иначе будет возникать ошибка, что устройство не найдено.  

Запуск терминала в LXDE осуществляется через меню Пуск:

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-2.jpg">
</p>

Переход в директорию и активация виртуального окружения показаны на скриншоте ниже

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-3.jpg">
</p>

### 1
> Твой коллега, ML-инженер, нашел в Интернете новую ML-модель, высоко оценил ее достоинства и разместил ее в папке modelToScan. Он попросил тебя протестировать эту модель на наличие вредоносного кода.
>
> Сколько критических уязвимостей из общего количества проверок инструмент modelaudit выдал при тестировании ML-модели pytorch_model.bin? Обрати внимание: чтобы получить корректный результат, нужно сканировать папку с моделью, а не сам файл модели.

> **Маска ответа:**
> xx_yy, где xx — число критических уязвимостей, yy — число общих проверок

Для использования `modelaudit` ознакомимся с параметрами запуска инструмента с помощью `--help`

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-4.jpg">
</p>

Далее запустим инструмент, указав в аргументах путь к *директории* с моделью

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-5.jpg">
</p>

После выполнения сканирования инструмент выводит отчёт, в котором выводит краткую сводку и подробный отчёт по найденным уязвимостям.

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-6.jpg">
</p>

По информации из отчёта, было осуществлено 35 проверок и найдено 12 уязвимостей, из которых 10 - критические.

Ответ: `10_35`

### 2
> Что ж, такие ML-модели нам не нужны.
> 
> Твоя следующая рабочая задача — сканирование квантованной LLM семейства Gemma, запущенной через Ollama, на наличие уязвимостей. Нужно протестировать её способность противостоять атаке на извлечение конфиденциальной информации, входящей в обучающую выборку LLM (проба leakreplay.GuardianCloze).
> 
> Какой детектор использовал сканер уязвимостей LLM garak при выполнении этой атаки?
> 
> Чтобы ответить на этот вопрос, найди и изучи отчёт garak о проведённом сканировании. Для запуска garak задай параметры сканирования в командной строке или создай конфигурационный файл .yaml. Используй эти параметры:
> - Тип модели: ollama
> - Имя модели: gemma:latest
> - Seed: укажи число, являющееся ответом на «главный вопрос жизни, Вселенной и всего такого»
> - Generations: 1
> - Verbose: 1

> Маска ответа:
> \*\*\*\*.*******************

 «Главный вопрос жизни, Вселенной и всего такого» - прекрасная отсылка к произведению "Автостопом по галактике". Под собой она скрывает число 42.  

Для получения информации об использовании сканера уязвимостей LLM garak следует воспользоваться командой `--help` и ознакомиться с параметрами запуска.

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-7.jpg">
</p>

В соответствии с информацией из `--help` и заданными условием параметрами команда будет выглядеть следующим образом:

    python -m garak --model_name gemma:latest --model_type ollama --probes leakreplay.GuardianCloze --seed 42 --generations 1 --verbose 

Также, перед тем, как выполнять данную команду необходимо запустить LLM.
Для этого необходимо выполнить команду 

    ollama run gemma:latest

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-9.jpg">
</p>

И затем запустить сканер:

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-8.jpg">
</p>

По результатам работы сканер создаст отчёт в формате html. Осуществим поиск по нему по ключу `detector`.

<p align="left">
  <img src="https://github.com/AronHopeless/CyberCamp2025_guide/blob/main/imgs/7-10.jpg">
</p>

Среди полученных строк находится искомый ответ.

Ответ: `base.TriggerListDetector`
 
### 3
> Теперь ты знаешь, насколько LLM уязвимы к атакам из предыдущего задания.
> 
> Перед тем как поместить ML-модель в реестр моделей, нужно её подписать. Используй инструмент **cosign** для подписи файла ML-модели `gemma-3n-E2B-it-Q2_K_L.gguf`, находящейся в папке gemma.
>
> Какую последнюю строку выдал cosign после проверки подписанного файла ML-модели?
>
> Команды для запуска:
> - Сгенерируй приватный и публичный ключи.
> - Используй приватный ключ для подписания файла ML-модели: `cosign sign-blob --key cosign_key_path.key --output-signature model_sig.sig model_path --tlog-upload=false`
> - Проверь подпись: `cosign verify-blob --key cosign_pub_path.pub --signature model_sig.sig model_path --insecure-ignore-tlog=true`

> Маска ответа:
> \*\*\*\*\*\*\*\* \*\*


Ответ: `base.TriggerListDetector`
